{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780130ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pathlib import Path  \n",
    "import os  \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "from torch.utils.data import Dataset, Dataloader\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from data_helper import SQLDataset_Humanitarian\n",
    "import mysql.connector as connector\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import cv2 \n",
    "import skimage\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816eb862",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be356abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser('~')\n",
    "os.chdir(home)\n",
    "\n",
    "train_img_path = Path(home) / ...\n",
    "dev_img_path = Path(home) / ...\n",
    "test_img_path = Path(home) / ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266bf130",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = '127.0.0.1'\n",
    "user = 'root' \n",
    "password = 'vasya1' \n",
    "database = 'ai_proj_2025' \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30052048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize/expore on train dataset\n",
    "trainset = SQLDataset_Humanitarian(...)\n",
    "devset = SQLDataset_Humanitarian(...)\n",
    "testset = SQLDataset_Humanitarian(...)\n",
    "\n",
    "trainloader = DataLoader(trainset, ...)\n",
    "devloader = DataLoader(devset, ...)\n",
    "testset = DataLoader(testset, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml feature engineering\n",
    "\n",
    "\n",
    "# deep feature engineering\n",
    "\n",
    "\n",
    "# concatenation\n",
    "train_img_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: should you use this fn or nan_euclidean_distances?\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance between two tensors.\n",
    "    \"\"\"\n",
    "    return torch.pow(x - y, 2).sum(dim=1)\n",
    "\n",
    "def compute_distance_matrix(anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Compute distance matrix between anchor, positive, and negative samples.\n",
    "    \"\"\"\n",
    "    distance_matrix = torch.zeros(anchor.size(0), 3)\n",
    "    distance_matrix[:, 0] = euclidean_distance(anchor, anchor)\n",
    "    distance_matrix[:, 1] = euclidean_distance(anchor, positive)\n",
    "    distance_matrix[:, 2] = euclidean_distance(anchor, negative)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112fa1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIPLET LOSS \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def batch_all_triplet_loss(anchor, positive, negative, margin=0.2):\n",
    "    '''\n",
    "    Computes triplet loss using the batch-all strategy\n",
    "    '''\n",
    "    dist_matrix = compute_distance_matrix(anchor, positive, negative)\n",
    "    loss = torch.max(torch.tensor(0.0), dist_matrix[:, 0] - dist_matrix[:, 1] + margin)\n",
    "    loss += torch.max(torch.tensor(0.0), dist_matrix[:, 0], dist_matrix[:, 2] + margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification model \n",
    "def train_random_forest(X_train, y_train):\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=..., criterion=..., max_depth=None)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    return rf_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch version for classification model\n",
    "class RF(nn.Module):\n",
    "    def __init__(self.rf):\n",
    "        ...\n",
    "    def forward():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bdab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: turn rf into pytorch model\n",
    "def dev(rf_model, dev_loader):\n",
    "    rf_model.to(device)\n",
    "    batch_size = dev_loader.batch_size\n",
    "    avg = 'macro' # used when computing certain accuracy metrics\n",
    "\n",
    "    eval_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for b, batch in tqdm(enumerate(dev_loader), total=len(dev_loader), desc=f'Processing dev set'):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label']\n",
    "\n",
    "        # apply transformations to images\n",
    "\n",
    "        final_feature_batch = ...\n",
    "\n",
    "        out = rf_model.transform(final_feature_batch)\n",
    "\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
