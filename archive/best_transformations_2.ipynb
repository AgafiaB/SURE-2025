{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4fdff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bowdenaa\\SURE-2025\\data_helper.py:41: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(not ((is_train and is_test) or (is_train and is_val) or (is_val and is_test)), 'a dataset can only be one of either train, test, or val')\n",
      "c:\\Users\\bowdenaa\\SURE-2025\\data_helper.py:144: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(img.expand_dims(axis=0).shape)==3, f\"wrong shaped image: {img.shape}\")\n",
      "c:\\Users\\bowdenaa\\SURE-2025\\data_helper.py:147: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(img.shape)==3, f\"wrong shaped image: {img.shape}\")\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import cv2 \n",
    "import skimage\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from data_helper import SQLDataset_Humanitarian\n",
    "import mysql.connector as connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset_without_emptyset(items):\n",
    "    '''\n",
    "    Returns the powerset of a list of items as a list of tuples, excluding the empty set\n",
    "    '''\n",
    "    combos = []\n",
    "    for i in range(len(items)):\n",
    "        combos.extend(list(combinations(items, len(items) - i)))\n",
    "    return combos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b506c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "host = '127.0.0.1'\n",
    "user = 'root' \n",
    "password = 'vasya1' \n",
    "database = 'ai_proj_2025' \n",
    "\n",
    "try:\n",
    "    conn = connector.connect(\n",
    "        host = host, \n",
    "        user = user, \n",
    "        password = password, \n",
    "        database = database\n",
    "    )\n",
    "    print('success')\n",
    "except connector.Error as err:\n",
    "    print(err)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78a9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SQLDataset_Humanitarian(conn = conn, \n",
    "                                  table_name = 'six_humanitarian_labels', \n",
    "                                    is_train = True,\n",
    "                                    is_val = False,\n",
    "                                    is_test = False,\n",
    "                                    label_col='image_human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce39f32",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1054 (42S22): Unknown column 'idx' in 'where clause'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# getting a pil image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img, label \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;241m21\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Convert the PIL image to a NumPy array and then to grayscale for use with OpenCV functions\u001b[39;00m\n\u001b[0;32m      4\u001b[0m im \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mOPEN(img))\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\SURE-2025\\data_helper.py:99\u001b[0m, in \u001b[0;36mSQLDataset_Humanitarian.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m         query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELECT \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m WHERE idx=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_sql_idxs[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m---> 99\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mexecute(query)\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;66;03m# read in image\u001b[39;00m\n\u001b[0;32m    102\u001b[0m         img_path, label \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchone()\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\mysql\\connector\\cursor.py:748\u001b[0m, in \u001b[0;36mMySQLCursor.execute\u001b[1;34m(self, operation, params, multi)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_iter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query_iter(stmt))\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mcmd_query(stmt))\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhave_next_result:\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\mysql\\connector\\opentelemetry\\context_propagation.py:102\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[1;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"Context propagation decorator.\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OTEL_ENABLED \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cnx\u001b[38;5;241m.\u001b[39motel_context_propagation:\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(cnx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    104\u001b[0m current_span \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mget_current_span()\n\u001b[0;32m    105\u001b[0m tp_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\mysql\\connector\\connection.py:861\u001b[0m, in \u001b[0;36mMySQLConnection.cmd_query\u001b[1;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[0;32m    859\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(packet)\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_cmd(ServerCmd\u001b[38;5;241m.\u001b[39mQUERY, query))\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProgrammingError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3948\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading local data is disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39mmsg:\n",
      "File \u001b[1;32mc:\\Users\\bowdenaa\\AppData\\Local\\anaconda3\\envs\\torch\\Lib\\site-packages\\mysql\\connector\\connection.py:637\u001b[0m, in \u001b[0;36mMySQLConnection._handle_result\u001b[1;34m(self, packet)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_eof(packet)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m packet[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m255\u001b[39m:\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_exception(packet)\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# We have a text result set\u001b[39;00m\n\u001b[0;32m    640\u001b[0m column_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mparse_column_count(packet)\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 1054 (42S22): Unknown column 'idx' in 'where clause'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# getting a pil image\n",
    "img, label = dataset.__getitem__(21)\n",
    "# Convert the PIL image to a NumPy array and then to grayscale for use with OpenCV functions\n",
    "im = np.array(Image.OPEN(img))\n",
    "\n",
    "if im.ndim == 3:\n",
    "    im_grey = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    im_grey = imtransforms_to_use = [cv2.HuMoments, skimage.feature.graycomatrix, \n",
    "                     cv2.calcHist, skimage.feature.local_binary_pattern]\n",
    "    \n",
    "# Compute Hu Moments\n",
    "hu_moments = cv2.HuMoments(cv2.moments(im_grey)).flatten()\n",
    "hu_moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def ensure_rgb(img):\n",
    "    \"\"\"\n",
    "    Ensures the input image is a 3-channel RGB numpy array.\n",
    "    If the image is grayscale (2D), it is converted to RGB.\n",
    "    If the image is already RGB, it is returned unchanged.\n",
    "    \"\"\"\n",
    "    if isinstance(img, np.ndarray):\n",
    "        if img.ndim == 2:  # Grayscale\n",
    "            assert(len(img.expand_dims(axis=0).shape)==3, f\"wrong shaped image: {img.shape}\")\n",
    "            return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB).expand_dims(axis=0)\n",
    "        elif img.ndim == 3 and img.shape[2] == 3:\n",
    "            assert(len(img.shape)==3, f\"wrong shaped image: {img.shape}\")\n",
    "            return img  # Already RGB\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported image shape for ensure_rgb: {}\".format(img.shape))\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a numpy ndarray.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef6c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO: check to ensure that the returned 2d data is correct for what you want \n",
    "\n",
    "def apply_transformations(images, combo):\n",
    "    features = []\n",
    "    for t in combo:\n",
    "        if t is cv2.HuMoments:\n",
    "            imgs_grey = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if img.ndim == 3 else img for img in images]\n",
    "            feats = [cv2.normalize(cv2.HuMoments(cv2.moments(im)).flatten(), None, 0, 255, cv2.NORM_MINMAX) for im in imgs_grey]\n",
    "        elif t is skimage.feature.graycomatrix:\n",
    "            imgs_grey = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if img.ndim == 3 else img for img in images]\n",
    "            dists, angles = [1], [0]\n",
    "            feats = []\n",
    "            for im in imgs_grey:\n",
    "                glcm = skimage.feature.graycomatrix(im, distances=dists, angles=angles, symmetric=True, normed=True)\n",
    "                diss = graycoprops(glcm, 'dissimilarity')\n",
    "                contrast = graycoprops(glcm, 'contrast')\n",
    "                cat = np.concatenate([diss, contrast], axis=1)\n",
    "                norm = cv2.normalize(cat, None, 0, 255, cv2.NORM_MINMAX).flatten()\n",
    "                feats.append(norm)\n",
    "        elif t is cv2.calcHist:\n",
    "            feats = [cv2.normalize(\n",
    "                        cv2.calcHist([img], [0,1,2], None, [8,8,8], [0,256]*3).flatten(),\n",
    "                        None, 0, 255, cv2.NORM_MINMAX).flatten() for img in images]\n",
    "        elif t is skimage.feature.local_binary_pattern:\n",
    "            imgs_grey = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) if img.ndim == 3 else img for img in images]\n",
    "            feats = []\n",
    "            for im in imgs_grey:\n",
    "                lbp = skimage.feature.local_binary_pattern(im, P=8, R=1)\n",
    "                hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0, 10))\n",
    "                feats.append(hist.flatten())\n",
    "        else:\n",
    "            print(t)\n",
    "            raise ValueError(f'Unsupported transformation: {t}')\n",
    "        \n",
    "        features.append(np.stack(feats))\n",
    "\n",
    "        for i, feature in enumerate(features): \n",
    "            if len(feature.shape) > 1:\n",
    "                features[i] = feature.flatten()\n",
    "                \n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "def best_transformation(transformations, class1_imgs, class2_imgs):\n",
    "    '''\n",
    "    Parameters: \n",
    "        transformations - a list of transformation functions\n",
    "        class1_imgs, class2_imgs - lists of ndarray images\n",
    "\n",
    "    Returns:\n",
    "        The transformation or combination of transformations (as a tuple) that \n",
    "        produces the most class separability\n",
    "    '''\n",
    "    class1_imgs = [ensure_rgb(img) for img in class1_imgs]\n",
    "    class2_imgs = [ensure_rgb(img) for img in class2_imgs]\n",
    "    class1_imgs = [cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX) for img in class1_imgs]\n",
    "    class2_imgs = [cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX) for img in class2_imgs]\n",
    "\n",
    "    combos = powerset_without_emptyset(transformations)\n",
    "    best_combo = None\n",
    "    \n",
    "    score_dict = {}\n",
    "    for combo in tqdm(combos, total=len(combos)):\n",
    "        \n",
    "        transformed1 = np.expand_dims(apply_transformations(class1_imgs, combo), axis=1)\n",
    "        transformed2 = np.expand_dims(apply_transformations(class2_imgs, combo), axis=1)\n",
    "        \n",
    "        inter_score = nan_euclidean_distances(transformed1, transformed2).mean()\n",
    "        intra_score1 = nan_euclidean_distances(transformed1, np.flip(transformed1, axis=0))\n",
    "        intra_score2 = nan_euclidean_distances(transformed2, np.flip(transformed2, axis=0))\n",
    "        score_dict[combo] = {\"inter-score\": inter_score, \"intra-score class 1\": intra_score1, \"intra-score class 2\": intra_score2}\n",
    "\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4304246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels for all images\n",
    "labels = [dataset._labels[i] for i in range(len(dataset))]\n",
    "\n",
    "# Choose two class indices (e.g., 0 and 1)\n",
    "class1_idx = 0\n",
    "class2_idx = 1\n",
    "\n",
    "# Get indices for each class\n",
    "class1_indices = [i for i, l in enumerate(labels) if l == class1_idx]\n",
    "class2_indices = [i for i, l in enumerate(labels) if l == class2_idx]\n",
    "\n",
    "# Get images for each class (as PIL Images)\n",
    "class1_imgs = [dataset[i][0] for i in class1_indices]\n",
    "class2_imgs = [dataset[i][0] for i in class2_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# convert pil images to np.array\n",
    "# TODO: change back to 244,244\n",
    "class1_imgs_arr = [np.array(img.resize((24,24))) for img in class1_imgs]\n",
    "class2_imgs_arr = [np.array(img.resize((24,24))) for img in class2_imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_imgs_arr[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [cv2.HuMoments, skimage.feature.graycomatrix, cv2.calcHist, skimage.feature.local_binary_pattern]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_combo = best_transformation(transforms, class1_imgs_arr, class2_imgs_arr)\n",
    "best_combo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b872bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize both images to (24, 24, 3) using cv2.resize, then flatten and reshape for distance calculation\n",
    "scores = []\n",
    "for img1, img2 in zip(class1_imgs_arr, class2_imgs_arr):\n",
    "    img1_resized = cv2.resize(img1, (24, 24)).reshape(-1, 1)\n",
    "    img2_resized = cv2.resize(img2, (24, 24)).reshape(-1, 1)\n",
    "    scores.append(nan_euclidean_distances(img1_resized, img2_resized ).mean())\n",
    "\n",
    "score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef42303",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(class1_imgs_arr) - 1):\n",
    "    img1_resized = cv2.resize(class1_imgs_arr[i], (24, 24)).reshape(-1, 1)\n",
    "    img2_resized = cv2.resize(class1_imgs_arr[i+1], (24, 24)).reshape(-1, 1)\n",
    "\n",
    "    scores.append(nan_euclidean_distances(img1_resized, img2_resized ).mean())\n",
    "\n",
    "score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049dc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2c406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe4e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
